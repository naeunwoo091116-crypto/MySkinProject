import requests
import logging
import base64
import io
from PIL import Image
from core.config import GPU_SERVER_URL, MODEL_CONFIGS

logger = logging.getLogger(__name__)

class RemoteAIService:
    """ì›ê²© GPU ì„œë²„ë¥¼ í†µí•œ AI ëª¨ë¸ ì¶”ë¡  ì„œë¹„ìŠ¤"""

    def __init__(self):
        self.base_url = GPU_SERVER_URL.rstrip('/')
        self.models = MODEL_CONFIGS # AnalysisServiceì—ì„œ models.keys()ë¥¼ ìˆœíšŒí•  ë•Œ í•„ìš”í•¨ (ì‹¤ì œ ëª¨ë¸ì€ ë¡œë“œí•˜ì§€ ì•ŠìŒ)
        logger.info(f"Using Remote AI Service at {self.base_url}")

    def predict_all_regions(self, pil_image):
        """
        ì›ê²© GPU ì„œë²„ì— ëª¨ë“  ë¶€ìœ„ ì˜ˆì¸¡ ìš”ì²­
        """
        try:
            # ì´ë¯¸ì§€ ë°”ì´íŠ¸ ë³€í™˜
            img_byte_arr = io.BytesIO()
            pil_image.save(img_byte_arr, format='JPEG')
            img_byte_arr = img_byte_arr.getvalue()

            files = {
                'file': ('image.jpg', img_byte_arr, 'image/jpeg')
            }

            logger.info("ğŸ“¡ Sending inference request to GPU server...")
            response = requests.post(f"{self.base_url}/api/v1/inference", files=files, timeout=30)
            
            if response.status_code == 200:
                result = response.json()
                if result.get("success"):
                    logger.info("âœ… Remote inference successful")
                    return result["predictions"]
                else:
                    raise Exception(f"GPU Server Error: {result}")
            else:
                raise Exception(f"HTTP {response.status_code}: {response.text}")

        except Exception as e:
            logger.error(f"âŒ Remote inference failed: {e}")
            raise e

    def preprocess_image(self, pil_image):
        """AnalysisService í˜¸í™˜ì„± ìœ ì§€ìš© (ì›ê²©ì—ì„œëŠ” ì‚¬ìš© ì•ˆ í•¨)"""
        return None 

    def predict(self, *args, **kwargs):
        """AnalysisService í˜¸í™˜ì„± ìœ ì§€ìš© (ì—ëŸ¬ ë°œìƒ)"""
        raise NotImplementedError("Remote service primarily uses predict_all_regions")

# Singleton (Mocking get_ai_service behaviors if needed directly, though usually called via factory)
def get_remote_ai_service():
    return RemoteAIService()
