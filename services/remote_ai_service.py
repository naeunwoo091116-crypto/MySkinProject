"""
ì›ê²© GPU ì„œë²„ AI ì¶”ë¡  ì„œë¹„ìŠ¤
GPU ì„œë²„ì˜ inference APIë¥¼ í˜¸ì¶œí•˜ì—¬ AI ë¶„ì„ ìˆ˜í–‰
"""
import requests
import io
from PIL import Image
from core.logger import setup_logger
from core.config import METRIC_NAMES
import os

logger = setup_logger(__name__)


class RemoteAIService:
    """ì›ê²© GPU ì„œë²„ AI ì„œë¹„ìŠ¤"""

    def __init__(self):
        # í™˜ê²½ ë³€ìˆ˜ì—ì„œ GPU ì„œë²„ URL ê°€ì ¸ì˜¤ê¸°
        self.gpu_server_url = os.getenv('GPU_SERVER_URL', 'http://localhost:8000')
        self.api_key = os.getenv('GPU_API_KEY', '')
        logger.info(f"ğŸŒ Remote AI Service initialized: {self.gpu_server_url}")

    def predict_all_regions(self, pil_image):
        """
        ì›ê²© GPU ì„œë²„ì—ì„œ ëª¨ë“  ë¶€ìœ„ ë¶„ì„

        Args:
            pil_image: PIL Image ê°ì²´

        Returns:
            dict: {zone: {cls_output, reg_output}}
        """
        try:
            # ì´ë¯¸ì§€ë¥¼ ë°”ì´íŠ¸ë¡œ ë³€í™˜
            img_byte_arr = io.BytesIO()
            pil_image.save(img_byte_arr, format='JPEG')
            img_byte_arr.seek(0)

            # GPU ì„œë²„ API í˜¸ì¶œ
            files = {'file': ('image.jpg', img_byte_arr, 'image/jpeg')}
            headers = {}
            if self.api_key:
                headers['X-API-Key'] = self.api_key

            logger.info(f"ğŸ“¡ Calling GPU server: {self.gpu_server_url}/api/v1/inference")
            response = requests.post(
                f"{self.gpu_server_url}/api/v1/inference",
                files=files,
                headers=headers,
                timeout=30
            )

            if response.status_code != 200:
                error_msg = response.json().get('message', 'Unknown error')
                raise Exception(f"GPU server error: {error_msg}")

            result = response.json()
            logger.info(f"âœ… GPU inference completed on {result.get('device', 'unknown')}")

            return result['predictions']

        except requests.exceptions.Timeout:
            logger.error("â±ï¸ GPU server timeout")
            raise Exception("GPU ì„œë²„ ì‘ë‹µ ì‹œê°„ ì´ˆê³¼")
        except requests.exceptions.ConnectionError:
            logger.error(f"ğŸ”Œ GPU server connection failed: {self.gpu_server_url}")
            raise Exception(f"GPU ì„œë²„ ì—°ê²° ì‹¤íŒ¨: {self.gpu_server_url}")
        except Exception as e:
            logger.error(f"âŒ Remote AI inference error: {e}")
            raise

    def health_check(self):
        """GPU ì„œë²„ ìƒíƒœ í™•ì¸"""
        try:
            response = requests.get(
                f"{self.gpu_server_url}/api/v1/health",
                timeout=5
            )
            if response.status_code == 200:
                return response.json()
            return {"status": "error", "message": f"HTTP {response.status_code}"}
        except Exception as e:
            return {"status": "error", "message": str(e)}


# ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
_remote_ai_service_instance = None


def get_remote_ai_service():
    """Remote AI ì„œë¹„ìŠ¤ ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    global _remote_ai_service_instance
    if _remote_ai_service_instance is None:
        _remote_ai_service_instance = RemoteAIService()
    return _remote_ai_service_instance
